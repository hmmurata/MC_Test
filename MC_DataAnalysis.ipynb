{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Inputs:\n",
    "bas_tot = 1000 # Total number of samples to baseline calculation\n",
    "fl_total = 24 # Total number of files\n",
    "\n",
    "# Pulse processing for each event\n",
    "# For this test, channels 1 and 3 will be used because the pulses are unipolar\n",
    "evt_smp = 100000 # Number of samples in an event\n",
    "evt_acc = 0 # accumulated number of events\n",
    "\n",
    "# Initialize energy arrays\n",
    "evt_total_est = 100 # Total number of events estimative per file (only for specify the length of array)\n",
    "ene_y1 = np.zeros(evt_total_est*fl_total) # Energy for each event in channel 1\n",
    "ene_y3 = np.zeros(evt_total_est*fl_total) # Energy for each event in channel 3\n",
    "\n",
    "# Process each csv file\n",
    "for chnk in range(fl_total):\n",
    "    fth_file = \"test_\" + str(chnk) + \".csv\" # csv file name\n",
    "    df = pd.read_csv(fth_file) # Data frame from file\n",
    "    content = df.values # Data frame to Numpy array\n",
    "\n",
    "    # Each column in Numpy array from Pandas data frame     \n",
    "    x0 = np.array(content[:,0]) # Horizontal scale -> T = 0.001E-08 (-5.000E-08 - -4.999E-08) \n",
    "    #y0 = np.array(content[:,1]) # Vertical - Signal 0\n",
    "    y1 = np.array(content[:,2]) # Vertical - Signal 1\n",
    "    #y2 = np.array(content[:,3]) # Vertical - Signal 2\n",
    "    y3 = np.array(content[:,4]) # Vertical - Signal 3\n",
    "\n",
    "    evt_tot = int(len(df.index)/evt_smp) # Total number of events    \n",
    "\n",
    "    clear_output(wait=False)\n",
    "    print(\"File name: {} - Processing {} event...\".format(fth_file, evt_tot))\n",
    "    print(\"Total number of events processed:\",evt_acc)\n",
    "    \n",
    "    # Process events\n",
    "    for evt_nb in range(evt_tot):        \n",
    "        print(\"File name: {} - Processing {}/{} event...\".format(fth_file, evt_nb+1, evt_tot))           \n",
    "        # List of events with problems\n",
    "        # Avoid these events\n",
    "        blc_lst = []\n",
    "        if chnk==7:\n",
    "            blc_lst = [1, 45, 46, 47] # chnk = 7\n",
    "        if chnk==17:\n",
    "            blc_lst = [41] # chnk = 17 (see error after this event. It is necessary remove row=4200000)\n",
    "        if chnk==18:\n",
    "            blc_lst = [52, 53] # chnk = 18\n",
    "        if chnk==19:\n",
    "            blc_lst = [98] # chnk = 19 (pulse with pile-up?)\n",
    "        if evt_nb in blc_lst:\n",
    "            print(\"File name: {} - Skipping {}/{} events...\".format(fth_file, evt_nb+1, evt_tot))\n",
    "            continue\n",
    "        \n",
    "        evt_sta = evt_nb * evt_smp # Event start\n",
    "        evt_end = evt_sta + evt_smp - 1 # Event end\n",
    "        evt_rng = range(evt_sta, evt_end) # Event range\n",
    "\n",
    "        # Baseline calculation - Average Moving Method\n",
    "        # In the Average Moving Method, the average is calculated from the beginning \n",
    "        # of the event to the sample referring to the trigger.\n",
    "        # But for simplification, the average will be calculated up to bas_tot sample \n",
    "        \n",
    "        bas_y1 = np.mean(y1[evt_sta:evt_sta + bas_tot]) # Baseline value for channel 1\n",
    "        bas_y3 = np.mean(y3[evt_sta:evt_sta + bas_tot]) # Baseline value for channel 3    \n",
    "        \n",
    "        # Threshold calculation \n",
    "        # For simplification the threshold will be estimed in 6 sigmas aprox.\n",
    "        thr_y1 = bas_y1 + 6 * np.std(y1[evt_sta:evt_sta + bas_tot]) # Threshold value for channel 1\n",
    "        thr_y3 = bas_y3 + 6 * np.std(y3[evt_sta:evt_sta + bas_tot]) # Threshold value for channel 3\n",
    "\n",
    "        # Trigger\n",
    "        trg_s1 = next(y for y in evt_rng if y1[y] > thr_y1) # Trigger sample for channel 1\n",
    "        trg_s3 = next(y for y in evt_rng if y3[y] > thr_y3) # Trigger sample for channel 3\n",
    "        trg_y1 = y1[trg_s1] # Trigger value for channel 1\n",
    "        trg_y3 = y3[trg_s3] # Trigger value for channel 3\n",
    "        trg_x1 = x0[trg_s1] # Trigger time for channel 1\n",
    "        trg_x3 = x0[trg_s3] # Trigger time for channel 3\n",
    "\n",
    "        # Energy calculation\n",
    "        ene_y1[evt_acc] = sum(y for y in y1[trg_s1:evt_end] if y > thr_y1) # Energy of event for channel 1\n",
    "        ene_y3[evt_acc] = sum(y for y in y3[trg_s3:evt_end] if y > thr_y3) # Energy of event for channel 3  \n",
    "\n",
    "        # # Select ONLY ONE event to view threshold in leading edge of pulse    \n",
    "        # smp_le_end = 10000 # Select the number of samples in leading edge for preview    \n",
    "        # smp_le_sta = 5000 # Select the number of samples in leading edge for preview    \n",
    "        # evt_sta = evt_nb * evt_smp + smp_le_sta# Event start\n",
    "        # evt_end = evt_sta + smp_le_end - 1 # Event end\n",
    "        # evt_rng = range(evt_sta, evt_end) # Event range\n",
    "\n",
    "        evt_acc = evt_acc + 1\n",
    "print(\"Total number of events:\",evt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save energy data\n",
    "dataset =pd.DataFrame({'ene_y1': ene_y1, 'ene_y3': ene_y3})\n",
    "ene_file = \"energy.csv\"\n",
    "dataset.to_csv(ene_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is not necessary if energy data has already been loaded.\n",
    "# Read energy data\n",
    "ene_file = \"energy.csv\"\n",
    "df = pd.read_csv(ene_file) # Data frame from file\n",
    "content = df.values\n",
    "ene_y1 = np.array(content[:,1])\n",
    "ene_y3 = np.array(content[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis from pulses energy data\n",
    "# 1-) Peak finder from energy spectra. This peak in x-axix will be the 511 keV\n",
    "# 2-) Calibrate spectrum to 511 keV energy\n",
    "# 3-) Isolate the 511 keV peak distribution from spectrum and calculates the baseline\n",
    "# 4-) There are a lot of methods to do a fit for baseline. Choose one\n",
    "# 5-) Remove the baseline from 511 keV peak distribution and calculates the Gaussian\n",
    "# 6-) Calculate FWHM and the energy resolution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Check scipy\n",
    "try:\n",
    "  import scipy\n",
    "except:\n",
    "  %pip install scipy\n",
    "  import scipy\n",
    "\n",
    "## Peak find from energy spectrum\n",
    "from scipy.signal import find_peaks\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.title('Energy spectra')\n",
    "\n",
    "# Channel 1:\n",
    "y0, binedges0 = np.histogram(ene_y1, bins = \"auto\")\n",
    "x0 = 0.5*(binedges0[1:] + binedges0[:-1])\n",
    "peaks0, _ = find_peaks(y0, prominence = 100)\n",
    "peak0 = np.amax(peaks0) # Find peak \n",
    "print(\"Channel 1: Peak index: {}, Non-calibrated x: {}, y: {}\".\\\n",
    "      format(peak0, x0[peak0], y0[peak0])) # Verify if there is only one peak found\n",
    "# divisor0 = x0[peak0]/511 # Calibrate in energy here\n",
    "divisor0 = x0[peak0]\n",
    "nx0 = np.true_divide(x0, divisor0)\n",
    "plt.plot(nx0, y0, label='Detector 0')\n",
    "plt.plot(nx0[peak0], y0[peak0], 'ro')\n",
    "plt.vlines(x = nx0[peak0], ymin = 0, ymax = y0[peak0], linestyles = \"dashed\", color = \"C0\")\n",
    "\n",
    "# Channel 3:\n",
    "y1, binedges1 = np.histogram(ene_y3, bins = \"auto\")\n",
    "x1 = 0.5*(binedges1[1:] + binedges1[:-1])\n",
    "peaks1, _ = find_peaks(y1, prominence = 100)\n",
    "peak1 = np.amax(peaks1) # Find 511 keV peak \n",
    "print(\"Channel 3: Peak index: {}, Non-calibrated x: {}, y: {}\".\\\n",
    "      format(peak1, x1[peak1], y1[peak1])) # Verify if there is only one peak found\n",
    "# divisor1 = x1[peak1] / 511 # Calibrate in energy here\n",
    "divisor1 = x1[peak1]\n",
    "nx1 = np.true_divide(x1, divisor1)\n",
    "plt.plot(nx1, y1, label='Detector 1')\n",
    "plt.plot(nx1[peak1], y1[peak1], 'ro')\n",
    "plt.vlines(x = nx1[peak1], ymin = 0, ymax = y1[peak1], linestyles = \"dashed\", color = \"C1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check lmfit\n",
    "try:\n",
    "  import lmfit\n",
    "except:\n",
    "  %pip install lmfit\n",
    "  import lmfit\n",
    "\n",
    "from lmfit.models import GaussianModel\n",
    "from scipy import sparse\n",
    "\n",
    "fig, a =  plt.subplots(1, 2, figsize = (12, 6))\n",
    "a[0].set_title(\"Channel 1 - Distribution around energy peak\", color = \"C0\")\n",
    "a[1].set_title(\"Channel 3 - Distribution around energy peak\", color = \"C1\")\n",
    "\n",
    "# Define lower limit and upper limit of distribution MANUALLY around xxx keV\n",
    "# Aprox. 3 sigmas around xxx keV\n",
    "# llim0 = 344 # For 511 keV example\n",
    "# ulim0 = 677 # For 511 keV example\n",
    "# llim1 = 340 # For 511 keV example\n",
    "# ulim1 = 682 # For 511 keV example\n",
    "llim0 = 0.66\n",
    "ulim0 = 1.34\n",
    "llim1 = 0.66\n",
    "ulim1 = 1.34\n",
    "pkx0 = nx0[(llim0 < nx0) & (nx0 < ulim0)]\n",
    "pky0 =  y0[(llim0 < nx0) & (nx0 < ulim0)]\n",
    "pkx1 = nx1[(llim1 < nx1) & (nx1 < ulim1)]\n",
    "pky1 =  y1[(llim1 < nx1) & (nx1 < ulim1)]\n",
    "\n",
    "# \"Asymmetric Least Squares Smoothing\" by P. Eilers and H. Boelens in 2005\n",
    "def baseline_als(y, lam, p, niter=10):\n",
    "    L = len(y)\n",
    "    D = sparse.diags([1, -2, 1],[0, -1, -2], shape=(L, L-2))\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = sparse.spdiags(w, 0, L, L)\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = sparse.linalg.spsolve(Z, w * y)\n",
    "        w = p * (y > z) + (1-p) * (y < z)\n",
    "    return z\n",
    "\n",
    "# Calculates baseline\n",
    "lbsl0 = baseline_als(pky0, 10000, 0.01)\n",
    "lbsl1 = baseline_als(pky1, 10000, 0.01)\n",
    "#plt.plot(pkx0, lbsl0, 'k--') # Plot baseline\n",
    "#plt.plot(pkx1, lbsl1, 'import matplotlib.pyplot as pltk--') # Plot baseline\n",
    "\n",
    "# Remove baseline\n",
    "spky0 = pky0 - lbsl0\n",
    "spky1 = pky1 - lbsl1\n",
    "a[0].plot(pkx0, spky0, color = 'C0', label = \"Source\") # Spectrum around 511 keV without baseline\n",
    "a[1].plot(pkx1, spky1, color = 'C1', label = \"Source\") # Spectrum around 511 keV without baseline\n",
    "\n",
    "# Report data analysis\n",
    "mod = GaussianModel()\n",
    "pars0 = mod.guess(spky0, x = pkx0)\n",
    "out0  = mod.fit(spky0, pars0, x = pkx0)\n",
    "print (\"Detector 0:\")\n",
    "print (out0.fit_report(min_correl=0.25))\n",
    "pars1 = mod.guess(spky1, x = pkx1)\n",
    "out1  = mod.fit(spky1, pars1, x = pkx1)\n",
    "print (\"\\nDetector 1:\")\n",
    "print (out1.fit_report(min_correl=0.25))\n",
    "\n",
    "oy0 = out0.best_fit + lbsl0 \n",
    "oy1 = out1.best_fit + lbsl1\n",
    "\n",
    "#plt.plot(pkx0, oy0, 'r-')\n",
    "#plt.plot(pkx1, oy1, 'r-')\n",
    "a[0].plot(pkx0, out0.best_fit , 'r--', label = \"Gaussian fit\")\n",
    "a[1].plot(pkx1, out1.best_fit , 'r--', label = \"Gaussian fit\")\n",
    "\n",
    "a[0].legend()\n",
    "a[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy resolution for xxx keV\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Energy spectra')\n",
    "plt.plot(nx0, y0, label = \"Channel 1\")\n",
    "plt.plot(nx1, y1, label = \"Channel 3\")\n",
    "plt.plot(pkx0, oy0, '--', label = \"Gaussian fit - Channel 1\")\n",
    "plt.plot(pkx1, oy1, '--', label = \"Gaussian fit - Channel 3\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"Energy resolution***:\")\n",
    "print(\"*** obs.: \")\n",
    "# 511 keV example:\n",
    "# res0 = out0.params['fwhm'].value / 511 * 100\n",
    "# sd_res0 = out0.params['fwhm'].stderr /511 * 100\n",
    "# print(\"Detector 0: {:.1f} +/- {:.1f} %\".format(res0, sd_res0,))\n",
    "# res1 = out1.params['fwhm'].value / 511 * 100\n",
    "# sd_res1 = out1.params['fwhm'].stderr /511 * 100\n",
    "# print(\"Detector 1: {:.1f} +/- {:.1f} %\".format(res1, sd_res1,))\n",
    "\n",
    "res0 = out0.params['fwhm'].value / 1 * 100\n",
    "sd_res0 = out0.params['fwhm'].stderr /1 * 100\n",
    "print(\"Detector 0: {:.1f} +/- {:.1f} %\".format(res0, sd_res0,))\n",
    "res1 = out1.params['fwhm'].value / 1 * 100\n",
    "sd_res1 = out1.params['fwhm'].stderr /1 * 100\n",
    "print(\"Detector 1: {:.1f} +/- {:.1f} %\".format(res1, sd_res1,))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
